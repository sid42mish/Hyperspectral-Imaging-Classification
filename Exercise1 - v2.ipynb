{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (145, 145, 200)\n",
      "y shape: (145, 145)\n"
     ]
    }
   ],
   "source": [
    "# Read the Data\n",
    "from scipy.io import loadmat\n",
    "\n",
    "def read_HSI():\n",
    "  X = loadmat('Indian_pines_corrected.mat')['indian_pines_corrected']\n",
    "  y = loadmat('Indian_pines_gt.mat')['indian_pines_gt']\n",
    "  print(f\"X shape: {X.shape}\\ny shape: {y.shape}\")\n",
    "  return X, y\n",
    "\n",
    "X, y = read_HSI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the Ground Truth\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(y, cmap='nipy_spectral')\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band1</th>\n",
       "      <th>band2</th>\n",
       "      <th>band3</th>\n",
       "      <th>band4</th>\n",
       "      <th>band5</th>\n",
       "      <th>band6</th>\n",
       "      <th>band7</th>\n",
       "      <th>band8</th>\n",
       "      <th>band9</th>\n",
       "      <th>band10</th>\n",
       "      <th>...</th>\n",
       "      <th>band192</th>\n",
       "      <th>band193</th>\n",
       "      <th>band194</th>\n",
       "      <th>band195</th>\n",
       "      <th>band196</th>\n",
       "      <th>band197</th>\n",
       "      <th>band198</th>\n",
       "      <th>band199</th>\n",
       "      <th>band200</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3172</td>\n",
       "      <td>4142</td>\n",
       "      <td>4506</td>\n",
       "      <td>4279</td>\n",
       "      <td>4782</td>\n",
       "      <td>5048</td>\n",
       "      <td>5213</td>\n",
       "      <td>5106</td>\n",
       "      <td>5053</td>\n",
       "      <td>4750</td>\n",
       "      <td>...</td>\n",
       "      <td>1094</td>\n",
       "      <td>1090</td>\n",
       "      <td>1112</td>\n",
       "      <td>1090</td>\n",
       "      <td>1062</td>\n",
       "      <td>1069</td>\n",
       "      <td>1057</td>\n",
       "      <td>1020</td>\n",
       "      <td>1020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2580</td>\n",
       "      <td>4266</td>\n",
       "      <td>4502</td>\n",
       "      <td>4426</td>\n",
       "      <td>4853</td>\n",
       "      <td>5249</td>\n",
       "      <td>5352</td>\n",
       "      <td>5353</td>\n",
       "      <td>5347</td>\n",
       "      <td>5065</td>\n",
       "      <td>...</td>\n",
       "      <td>1108</td>\n",
       "      <td>1104</td>\n",
       "      <td>1117</td>\n",
       "      <td>1091</td>\n",
       "      <td>1079</td>\n",
       "      <td>1085</td>\n",
       "      <td>1064</td>\n",
       "      <td>1029</td>\n",
       "      <td>1020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3687</td>\n",
       "      <td>4266</td>\n",
       "      <td>4421</td>\n",
       "      <td>4498</td>\n",
       "      <td>5019</td>\n",
       "      <td>5293</td>\n",
       "      <td>5438</td>\n",
       "      <td>5427</td>\n",
       "      <td>5383</td>\n",
       "      <td>5132</td>\n",
       "      <td>...</td>\n",
       "      <td>1111</td>\n",
       "      <td>1114</td>\n",
       "      <td>1114</td>\n",
       "      <td>1100</td>\n",
       "      <td>1065</td>\n",
       "      <td>1092</td>\n",
       "      <td>1061</td>\n",
       "      <td>1030</td>\n",
       "      <td>1016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2749</td>\n",
       "      <td>4258</td>\n",
       "      <td>4603</td>\n",
       "      <td>4493</td>\n",
       "      <td>4958</td>\n",
       "      <td>5234</td>\n",
       "      <td>5417</td>\n",
       "      <td>5355</td>\n",
       "      <td>5349</td>\n",
       "      <td>5096</td>\n",
       "      <td>...</td>\n",
       "      <td>1122</td>\n",
       "      <td>1108</td>\n",
       "      <td>1109</td>\n",
       "      <td>1109</td>\n",
       "      <td>1071</td>\n",
       "      <td>1088</td>\n",
       "      <td>1060</td>\n",
       "      <td>1030</td>\n",
       "      <td>1006</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2746</td>\n",
       "      <td>4018</td>\n",
       "      <td>4675</td>\n",
       "      <td>4417</td>\n",
       "      <td>4886</td>\n",
       "      <td>5117</td>\n",
       "      <td>5215</td>\n",
       "      <td>5096</td>\n",
       "      <td>5098</td>\n",
       "      <td>4834</td>\n",
       "      <td>...</td>\n",
       "      <td>1110</td>\n",
       "      <td>1107</td>\n",
       "      <td>1112</td>\n",
       "      <td>1094</td>\n",
       "      <td>1072</td>\n",
       "      <td>1087</td>\n",
       "      <td>1052</td>\n",
       "      <td>1034</td>\n",
       "      <td>1019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   band1  band2  band3  band4  band5  band6  band7  band8  band9  band10  ...  \\\n",
       "0   3172   4142   4506   4279   4782   5048   5213   5106   5053    4750  ...   \n",
       "1   2580   4266   4502   4426   4853   5249   5352   5353   5347    5065  ...   \n",
       "2   3687   4266   4421   4498   5019   5293   5438   5427   5383    5132  ...   \n",
       "3   2749   4258   4603   4493   4958   5234   5417   5355   5349    5096  ...   \n",
       "4   2746   4018   4675   4417   4886   5117   5215   5096   5098    4834  ...   \n",
       "\n",
       "   band192  band193  band194  band195  band196  band197  band198  band199  \\\n",
       "0     1094     1090     1112     1090     1062     1069     1057     1020   \n",
       "1     1108     1104     1117     1091     1079     1085     1064     1029   \n",
       "2     1111     1114     1114     1100     1065     1092     1061     1030   \n",
       "3     1122     1108     1109     1109     1071     1088     1060     1030   \n",
       "4     1110     1107     1112     1094     1072     1087     1052     1034   \n",
       "\n",
       "   band200  class  \n",
       "0     1020      3  \n",
       "1     1020      3  \n",
       "2     1016      3  \n",
       "3     1006      3  \n",
       "4     1019      3  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the dataset into csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_pixels(X, y):\n",
    "  q = X.reshape(-1, X.shape[2])\n",
    "  df = pd.DataFrame(data = q)\n",
    "  df = pd.concat([df, pd.DataFrame(data = y.ravel())], axis=1)\n",
    "  df.columns= [f'band{i}' for i in range(1, 1+X.shape[2])]+['class']\n",
    "  df.to_csv('Dataset.csv')\n",
    "  return df\n",
    "  \n",
    "df = extract_pixels(X, y)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band1</th>\n",
       "      <th>band2</th>\n",
       "      <th>band3</th>\n",
       "      <th>band4</th>\n",
       "      <th>band5</th>\n",
       "      <th>band6</th>\n",
       "      <th>band7</th>\n",
       "      <th>band8</th>\n",
       "      <th>band9</th>\n",
       "      <th>band10</th>\n",
       "      <th>...</th>\n",
       "      <th>band192</th>\n",
       "      <th>band193</th>\n",
       "      <th>band194</th>\n",
       "      <th>band195</th>\n",
       "      <th>band196</th>\n",
       "      <th>band197</th>\n",
       "      <th>band198</th>\n",
       "      <th>band199</th>\n",
       "      <th>band200</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3172</td>\n",
       "      <td>4142</td>\n",
       "      <td>4506</td>\n",
       "      <td>4279</td>\n",
       "      <td>4782</td>\n",
       "      <td>5048</td>\n",
       "      <td>5213</td>\n",
       "      <td>5106</td>\n",
       "      <td>5053</td>\n",
       "      <td>4750</td>\n",
       "      <td>...</td>\n",
       "      <td>1094</td>\n",
       "      <td>1090</td>\n",
       "      <td>1112</td>\n",
       "      <td>1090</td>\n",
       "      <td>1062</td>\n",
       "      <td>1069</td>\n",
       "      <td>1057</td>\n",
       "      <td>1020</td>\n",
       "      <td>1020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2580</td>\n",
       "      <td>4266</td>\n",
       "      <td>4502</td>\n",
       "      <td>4426</td>\n",
       "      <td>4853</td>\n",
       "      <td>5249</td>\n",
       "      <td>5352</td>\n",
       "      <td>5353</td>\n",
       "      <td>5347</td>\n",
       "      <td>5065</td>\n",
       "      <td>...</td>\n",
       "      <td>1108</td>\n",
       "      <td>1104</td>\n",
       "      <td>1117</td>\n",
       "      <td>1091</td>\n",
       "      <td>1079</td>\n",
       "      <td>1085</td>\n",
       "      <td>1064</td>\n",
       "      <td>1029</td>\n",
       "      <td>1020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3687</td>\n",
       "      <td>4266</td>\n",
       "      <td>4421</td>\n",
       "      <td>4498</td>\n",
       "      <td>5019</td>\n",
       "      <td>5293</td>\n",
       "      <td>5438</td>\n",
       "      <td>5427</td>\n",
       "      <td>5383</td>\n",
       "      <td>5132</td>\n",
       "      <td>...</td>\n",
       "      <td>1111</td>\n",
       "      <td>1114</td>\n",
       "      <td>1114</td>\n",
       "      <td>1100</td>\n",
       "      <td>1065</td>\n",
       "      <td>1092</td>\n",
       "      <td>1061</td>\n",
       "      <td>1030</td>\n",
       "      <td>1016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2749</td>\n",
       "      <td>4258</td>\n",
       "      <td>4603</td>\n",
       "      <td>4493</td>\n",
       "      <td>4958</td>\n",
       "      <td>5234</td>\n",
       "      <td>5417</td>\n",
       "      <td>5355</td>\n",
       "      <td>5349</td>\n",
       "      <td>5096</td>\n",
       "      <td>...</td>\n",
       "      <td>1122</td>\n",
       "      <td>1108</td>\n",
       "      <td>1109</td>\n",
       "      <td>1109</td>\n",
       "      <td>1071</td>\n",
       "      <td>1088</td>\n",
       "      <td>1060</td>\n",
       "      <td>1030</td>\n",
       "      <td>1006</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2746</td>\n",
       "      <td>4018</td>\n",
       "      <td>4675</td>\n",
       "      <td>4417</td>\n",
       "      <td>4886</td>\n",
       "      <td>5117</td>\n",
       "      <td>5215</td>\n",
       "      <td>5096</td>\n",
       "      <td>5098</td>\n",
       "      <td>4834</td>\n",
       "      <td>...</td>\n",
       "      <td>1110</td>\n",
       "      <td>1107</td>\n",
       "      <td>1112</td>\n",
       "      <td>1094</td>\n",
       "      <td>1072</td>\n",
       "      <td>1087</td>\n",
       "      <td>1052</td>\n",
       "      <td>1034</td>\n",
       "      <td>1019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20763</td>\n",
       "      <td>2732</td>\n",
       "      <td>4242</td>\n",
       "      <td>4113</td>\n",
       "      <td>4045</td>\n",
       "      <td>4510</td>\n",
       "      <td>4811</td>\n",
       "      <td>4812</td>\n",
       "      <td>4719</td>\n",
       "      <td>4631</td>\n",
       "      <td>4512</td>\n",
       "      <td>...</td>\n",
       "      <td>1078</td>\n",
       "      <td>1068</td>\n",
       "      <td>1077</td>\n",
       "      <td>1062</td>\n",
       "      <td>1050</td>\n",
       "      <td>1056</td>\n",
       "      <td>1039</td>\n",
       "      <td>1014</td>\n",
       "      <td>1008</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20764</td>\n",
       "      <td>2561</td>\n",
       "      <td>4242</td>\n",
       "      <td>4290</td>\n",
       "      <td>4255</td>\n",
       "      <td>4520</td>\n",
       "      <td>4865</td>\n",
       "      <td>4918</td>\n",
       "      <td>4819</td>\n",
       "      <td>4908</td>\n",
       "      <td>4586</td>\n",
       "      <td>...</td>\n",
       "      <td>1084</td>\n",
       "      <td>1082</td>\n",
       "      <td>1101</td>\n",
       "      <td>1071</td>\n",
       "      <td>1057</td>\n",
       "      <td>1058</td>\n",
       "      <td>1054</td>\n",
       "      <td>1018</td>\n",
       "      <td>1004</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20765</td>\n",
       "      <td>2564</td>\n",
       "      <td>4238</td>\n",
       "      <td>4290</td>\n",
       "      <td>4183</td>\n",
       "      <td>4634</td>\n",
       "      <td>4919</td>\n",
       "      <td>5085</td>\n",
       "      <td>4977</td>\n",
       "      <td>4841</td>\n",
       "      <td>4625</td>\n",
       "      <td>...</td>\n",
       "      <td>1091</td>\n",
       "      <td>1091</td>\n",
       "      <td>1096</td>\n",
       "      <td>1076</td>\n",
       "      <td>1061</td>\n",
       "      <td>1067</td>\n",
       "      <td>1042</td>\n",
       "      <td>1023</td>\n",
       "      <td>1018</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20766</td>\n",
       "      <td>2735</td>\n",
       "      <td>4114</td>\n",
       "      <td>4295</td>\n",
       "      <td>4192</td>\n",
       "      <td>4643</td>\n",
       "      <td>4973</td>\n",
       "      <td>5052</td>\n",
       "      <td>4993</td>\n",
       "      <td>4912</td>\n",
       "      <td>4683</td>\n",
       "      <td>...</td>\n",
       "      <td>1089</td>\n",
       "      <td>1092</td>\n",
       "      <td>1102</td>\n",
       "      <td>1080</td>\n",
       "      <td>1066</td>\n",
       "      <td>1068</td>\n",
       "      <td>1041</td>\n",
       "      <td>1024</td>\n",
       "      <td>1018</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20767</td>\n",
       "      <td>2732</td>\n",
       "      <td>4122</td>\n",
       "      <td>4388</td>\n",
       "      <td>4335</td>\n",
       "      <td>4734</td>\n",
       "      <td>5017</td>\n",
       "      <td>5123</td>\n",
       "      <td>5090</td>\n",
       "      <td>5105</td>\n",
       "      <td>4806</td>\n",
       "      <td>...</td>\n",
       "      <td>1095</td>\n",
       "      <td>1108</td>\n",
       "      <td>1107</td>\n",
       "      <td>1085</td>\n",
       "      <td>1054</td>\n",
       "      <td>1080</td>\n",
       "      <td>1054</td>\n",
       "      <td>1024</td>\n",
       "      <td>1014</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10249 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       band1  band2  band3  band4  band5  band6  band7  band8  band9  band10  \\\n",
       "0       3172   4142   4506   4279   4782   5048   5213   5106   5053    4750   \n",
       "1       2580   4266   4502   4426   4853   5249   5352   5353   5347    5065   \n",
       "2       3687   4266   4421   4498   5019   5293   5438   5427   5383    5132   \n",
       "3       2749   4258   4603   4493   4958   5234   5417   5355   5349    5096   \n",
       "4       2746   4018   4675   4417   4886   5117   5215   5096   5098    4834   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...     ...   \n",
       "20763   2732   4242   4113   4045   4510   4811   4812   4719   4631    4512   \n",
       "20764   2561   4242   4290   4255   4520   4865   4918   4819   4908    4586   \n",
       "20765   2564   4238   4290   4183   4634   4919   5085   4977   4841    4625   \n",
       "20766   2735   4114   4295   4192   4643   4973   5052   4993   4912    4683   \n",
       "20767   2732   4122   4388   4335   4734   5017   5123   5090   5105    4806   \n",
       "\n",
       "       ...  band192  band193  band194  band195  band196  band197  band198  \\\n",
       "0      ...     1094     1090     1112     1090     1062     1069     1057   \n",
       "1      ...     1108     1104     1117     1091     1079     1085     1064   \n",
       "2      ...     1111     1114     1114     1100     1065     1092     1061   \n",
       "3      ...     1122     1108     1109     1109     1071     1088     1060   \n",
       "4      ...     1110     1107     1112     1094     1072     1087     1052   \n",
       "...    ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "20763  ...     1078     1068     1077     1062     1050     1056     1039   \n",
       "20764  ...     1084     1082     1101     1071     1057     1058     1054   \n",
       "20765  ...     1091     1091     1096     1076     1061     1067     1042   \n",
       "20766  ...     1089     1092     1102     1080     1066     1068     1041   \n",
       "20767  ...     1095     1108     1107     1085     1054     1080     1054   \n",
       "\n",
       "       band199  band200  class  \n",
       "0         1020     1020      3  \n",
       "1         1029     1020      3  \n",
       "2         1030     1016      3  \n",
       "3         1030     1006      3  \n",
       "4         1034     1019      3  \n",
       "...        ...      ...    ...  \n",
       "20763     1014     1008     10  \n",
       "20764     1018     1004     10  \n",
       "20765     1023     1018     10  \n",
       "20766     1024     1018     10  \n",
       "20767     1024     1014     10  \n",
       "\n",
       "[10249 rows x 201 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove class label 0 from the data\n",
    "df_new = df[df['class']!=0]\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=10240, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the SVM model on training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  19    0    0    0    0    0    0    7    0    0    0    1    0    0\n",
      "     0    0]\n",
      " [   0  747    7   12    0    0    0    0    0   27   61    3    0    0\n",
      "     0    0]\n",
      " [   0   15  425   13    0    0    0    0    0    3   33    9    0    0\n",
      "     0    0]\n",
      " [   0    3   24  105    0    1    0    1    0    2    5    1    0    0\n",
      "     0    0]\n",
      " [   0    1    0    1  280    1    0    0    0    1    2    3    0    1\n",
      "     0    0]\n",
      " [   0    0    0    0    4  429    0    0    0    0    0    0    0    1\n",
      "     4    0]\n",
      " [   0    0    0    0    1    0   12    4    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    1    0    0  286    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    1    0    0    5    0    0    0    6    0\n",
      "     0    0]\n",
      " [   0   23    1    1    0    3    0    0    1  487   65    2    0    0\n",
      "     0    0]\n",
      " [   0   53   24    1    5    5    0    0    1   48 1328    6    0    0\n",
      "     2    0]\n",
      " [   0    5    8    6    0    0    0    0    0    5   13  317    0    0\n",
      "     1    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0  122    0\n",
      "     0    0]\n",
      " [   0    0    0    0    4    0    0    0    0    0    0    0    0  736\n",
      "    19    0]\n",
      " [   0    0    1    3    5   10    0    0    2    0    1    0    2   43\n",
      "   165    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0    0    0\n",
      "     0   55]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8972357723577236"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying PCA with different prime components (p) on SVM rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imssi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  10    0    0    0    0    0    0   16    0    0    1    0    0    0\n",
      "     0    0]\n",
      " [   0  426   79   28    0    1    0    0    0   61  217   45    0    0\n",
      "     0    0]\n",
      " [   0   86  274   15    0    1    0    0    0   14   86   22    0    0\n",
      "     0    0]\n",
      " [   1   23   19   56    8    1    0    0    0    9   12   13    0    0\n",
      "     0    0]\n",
      " [   0    3    0    1  247    5    0    0    0    1    5    1    0   14\n",
      "    13    0]\n",
      " [   0    5    0    5    5  367    0    0    1    0    6    1    0   15\n",
      "    33    0]\n",
      " [   1    0    0    0    1    0    7    8    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [  10    1    0    0    3    0    2  266    0    0    5    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    1    2    0    0    4    0    0    0    3    0\n",
      "     2    0]\n",
      " [   0   46   32   11    1    2    0    0    0  380   88   23    0    0\n",
      "     0    0]\n",
      " [   0  124   63    6    4    8    1    0    0   95 1145   24    0    0\n",
      "     3    0]\n",
      " [   0   81   30   14    1    0    0    0    0   35   76  117    1    0\n",
      "     0    1]\n",
      " [   0    0    0    0    1    0    0    0    0    0    1    0  112    0\n",
      "     9    0]\n",
      " [   0    1    0    0   30    7    0    0    0    0    2    0    0  686\n",
      "    33    0]\n",
      " [   0    8    0    2   12   46    0    0    2    0    4    0    8   56\n",
      "    94    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0   12    0    0    0\n",
      "     0   43]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6884552845528455"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p=5\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 5)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imssi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  17    0    0    0    0    0    0    9    0    0    1    0    0    0\n",
      "     0    0]\n",
      " [   0  600   22   13    0    0    0    0    0   53  128   40    1    0\n",
      "     0    0]\n",
      " [   0   35  359   17    0    0    0    0    0   11   62   14    0    0\n",
      "     0    0]\n",
      " [   0   14   21   82    0    1    0    1    0    1   12   10    0    0\n",
      "     0    0]\n",
      " [   0    4    0    1  258    5    0    0    0    1    3    1    0    8\n",
      "     9    0]\n",
      " [   0    1    0    3    2  387    0    0    0    0    1    0    0    9\n",
      "    35    0]\n",
      " [   0    0    0    0    1    0   10    6    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   6    0    0    0    5    0    1  273    0    0    2    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    7    0    0    0    4    0\n",
      "     1    0]\n",
      " [   0   43   12    3    1    1    0    0    1  444   68   10    0    0\n",
      "     0    0]\n",
      " [   0  151  101    5    4    8    0    0    1   66 1115   20    0    0\n",
      "     2    0]\n",
      " [   0   67   25    6    1    0    0    0    0   18   53  184    0    0\n",
      "     1    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0  119    0\n",
      "     3    0]\n",
      " [   0    0    0    0   21    1    0    0    0    0    1    0    0  694\n",
      "    42    0]\n",
      " [   0    2    0    1   12   39    0    0    1    0    4    0    4   47\n",
      "   122    0]\n",
      " [   0    3    0    0    0    0    0    0    0    0   10    0    0    0\n",
      "     0   43]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7665040650406504"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p=10\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 10)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imssi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  15    0    0    0    0    0    0   11    0    1    0    0    0    0\n",
      "     0    0]\n",
      " [   0  605   18    8    0    0    0    0    0   49  140   36    1    0\n",
      "     0    0]\n",
      " [   0   38  364   15    0    0    0    0    0   12   50   19    0    0\n",
      "     0    0]\n",
      " [   0   20   14   84    1    1    0    1    0    3    8   10    0    0\n",
      "     0    0]\n",
      " [   0    3    0    1  259    3    0    0    0    1    2    1    0   12\n",
      "     8    0]\n",
      " [   0    0    0    2    6  409    0    0    0    0    1    0    0    5\n",
      "    15    0]\n",
      " [   0    0    0    0    1    0   11    5    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   6    0    0    0    3    0    0  277    0    0    1    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    1    0    0    6    0    0    0    5    0\n",
      "     0    0]\n",
      " [   0   46    7    2    2    2    0    0    0  446   67   11    0    0\n",
      "     0    0]\n",
      " [   0  135   90    1    3    8    0    0    1   66 1148   19    0    0\n",
      "     2    0]\n",
      " [   0   69   32    4    1    0    0    0    0   18   35  195    0    0\n",
      "     1    1]\n",
      " [   0    0    0    0    0    0    0    0    1    0    1    0  119    0\n",
      "     2    0]\n",
      " [   0    0    0    0   18    0    0    0    0    0    1    0    0  706\n",
      "    34    0]\n",
      " [   0    2    1    0   15   33    0    0    1    0    4    2    4   39\n",
      "   131    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    9    0    0    0\n",
      "     0   46]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7839024390243903"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p=15\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 15)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imssi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  18    0    0    0    0    0    0    8    0    1    0    0    0    0\n",
      "     0    0]\n",
      " [   0  621   16    9    0    0    0    0    0   51  131   28    1    0\n",
      "     0    0]\n",
      " [   0   29  365   16    0    0    0    0    0   16   55   17    0    0\n",
      "     0    0]\n",
      " [   0   21   18   85    1    1    0    1    0    3    6    6    0    0\n",
      "     0    0]\n",
      " [   0    2    0    0  256    6    0    0    0    1    3    2    0   12\n",
      "     8    0]\n",
      " [   0    1    0    2    5  414    0    0    0    0    0    0    0    3\n",
      "    13    0]\n",
      " [   1    0    0    0    1    0   11    4    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   7    0    0    0    2    0    0  277    0    0    1    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    1    0    0    6    0    0    0    5    0\n",
      "     0    0]\n",
      " [   0   56    6    1    2    2    0    0    0  434   73    9    0    0\n",
      "     0    0]\n",
      " [   0  116   78    2    3    6    0    0    1   59 1195    9    0    0\n",
      "     4    0]\n",
      " [   0   39   31    4    1    0    0    0    0   22   23  234    0    0\n",
      "     1    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0  120    0\n",
      "     2    0]\n",
      " [   0    0    0    0   15    0    0    0    0    0    1    0    0  694\n",
      "    49    0]\n",
      " [   0    2    0    0   10   28    0    0    2    1    4    1    2   37\n",
      "   145    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    7    0    0    0\n",
      "     0   48]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8004878048780488"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p=20\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 20)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imssi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  16    0    0    0    0    0    0   10    0    1    0    0    0    0\n",
      "     0    0]\n",
      " [   0  644   17   10    0    1    0    0    0   52  113   20    0    0\n",
      "     0    0]\n",
      " [   0   35  367   15    0    0    0    0    0   10   54   17    0    0\n",
      "     0    0]\n",
      " [   0   24   13   87    1    1    0    1    0    3    6    6    0    0\n",
      "     0    0]\n",
      " [   0    2    0    1  261    4    0    0    0    1    2    2    0   14\n",
      "     3    0]\n",
      " [   0    1    0    1    4  421    0    0    0    0    0    0    0    2\n",
      "     9    0]\n",
      " [   1    0    0    0    1    0   12    3    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   4    0    0    0    1    0    0  280    0    0    2    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    6    0    0    0    6    0\n",
      "     0    0]\n",
      " [   0   52    4    1    2    2    0    0    0  448   63   11    0    0\n",
      "     0    0]\n",
      " [   0  108   73    4    3    4    0    0    1   57 1207   11    0    0\n",
      "     5    0]\n",
      " [   0   37   21    6    1    0    0    0    0   14   28  247    0    0\n",
      "     1    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0  121    0\n",
      "     1    0]\n",
      " [   0    0    0    0   12    0    0    0    0    0    1    0    0  707\n",
      "    39    0]\n",
      " [   0    2    0    1    9   22    0    0    2    1    3    1    4   43\n",
      "   144    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    6    0    0    0\n",
      "     0   49]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8157723577235773"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p=25\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 25)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imssi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  17    0    0    0    0    0    0    9    0    1    0    0    0    0\n",
      "     0    0]\n",
      " [   0  658   14    9    0    0    0    0    0   51  107   18    0    0\n",
      "     0    0]\n",
      " [   0   27  371   19    0    0    0    0    0    7   54   20    0    0\n",
      "     0    0]\n",
      " [   0   12   18   94    0    1    0    1    0    2    7    7    0    0\n",
      "     0    0]\n",
      " [   0    1    0    0  266    5    0    0    0    1    3    2    0    9\n",
      "     3    0]\n",
      " [   0    1    0    1    4  418    0    0    0    0    0    0    0    2\n",
      "    12    0]\n",
      " [   1    0    0    0    1    0   12    3    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   4    0    0    0    1    0    0  280    0    0    2    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    6    0    0    0    6    0\n",
      "     0    0]\n",
      " [   0   48    3    1    1    2    0    0    1  455   62   10    0    0\n",
      "     0    0]\n",
      " [   0  114   49    4    4    7    0    0    0   49 1235    8    0    0\n",
      "     3    0]\n",
      " [   0   28   20    8    1    0    0    0    0   10   26  261    0    0\n",
      "     1    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0  122    0\n",
      "     0    0]\n",
      " [   0    0    0    0    9    0    0    0    0    0    1    0    0  712\n",
      "    37    0]\n",
      " [   0    0    0    1    7   23    0    0    2    1    3    0    2   46\n",
      "   147    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    6    0    0    0\n",
      "     0   49]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8297560975609756"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p=30\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 30)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imssi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  16    0    0    0    0    0    0   10    0    1    0    0    0    0\n",
      "     0    0]\n",
      " [   0  677   11   10    0    0    0    0    0   43   98   18    0    0\n",
      "     0    0]\n",
      " [   0   32  370   17    0    0    0    0    0    5   57   17    0    0\n",
      "     0    0]\n",
      " [   0   11   18   95    0    1    0    1    0    3    6    7    0    0\n",
      "     0    0]\n",
      " [   0    2    0    0  268    5    0    0    0    1    2    2    0    8\n",
      "     2    0]\n",
      " [   0    1    0    1    4  419    0    0    0    0    0    0    0    3\n",
      "    10    0]\n",
      " [   1    0    0    0    1    0   12    3    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   4    0    0    0    2    0    0  280    0    0    1    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    7    0    0    0    5    0\n",
      "     0    0]\n",
      " [   0   44    3    1    1    2    0    0    1  457   63   11    0    0\n",
      "     0    0]\n",
      " [   0   99   51    3    4    7    0    0    1   50 1245   10    0    0\n",
      "     3    0]\n",
      " [   0   17   16    7    1    0    0    0    0    8   20  284    0    0\n",
      "     1    2]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0  122    0\n",
      "     0    0]\n",
      " [   0    0    0    0    7    0    0    0    0    0    1    0    0  718\n",
      "    33    0]\n",
      " [   0    1    0    2    4   19    0    0    2    1    2    0    3   44\n",
      "   154    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    6    0    0    0\n",
      "     0   50]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8413008130081301"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p=35\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 35)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imssi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  16    0    0    0    0    0    0   10    0    1    0    0    0    0\n",
      "     0    0]\n",
      " [   0  685   10   12    0    0    0    0    0   40   93   17    0    0\n",
      "     0    0]\n",
      " [   0   27  383   17    0    0    0    0    0    5   45   21    0    0\n",
      "     0    0]\n",
      " [   0   12   24   94    0    1    0    1    0    1    4    5    0    0\n",
      "     0    0]\n",
      " [   0    2    0    1  270    5    0    0    0    0    4    1    0    5\n",
      "     2    0]\n",
      " [   0    0    0    2    4  420    0    0    0    0    0    0    0    3\n",
      "     9    0]\n",
      " [   0    0    0    0    1    0   12    4    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   4    0    0    0    2    0    0  280    0    0    1    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    6    0    0    0    6    0\n",
      "     0    0]\n",
      " [   0   34    2    1    0    2    0    0    1  472   60   11    0    0\n",
      "     0    0]\n",
      " [   0   98   44    3    4    7    0    0    1   58 1248    7    0    0\n",
      "     3    0]\n",
      " [   0   15   16    8    1    0    0    0    0    9   13  291    0    0\n",
      "     1    2]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0  122    0\n",
      "     0    0]\n",
      " [   0    0    0    0    7    0    0    0    0    0    2    0    0  720\n",
      "    30    0]\n",
      " [   0    0    0    2    3   15    0    0    2    1    2    0    3   43\n",
      "   161    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    5    0    0    0\n",
      "     0   51]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8505691056910569"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p=40\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 40)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imssi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  18    0    0    0    0    0    0    8    0    1    0    0    0    0\n",
      "     0    0]\n",
      " [   0  690   13   10    0    0    0    0    0   42   89   13    0    0\n",
      "     0    0]\n",
      " [   0   21  394   16    0    0    0    0    0    5   44   18    0    0\n",
      "     0    0]\n",
      " [   0   10   25   92    0    1    0    1    0    3    5    5    0    0\n",
      "     0    0]\n",
      " [   0    3    0    0  272    5    0    0    0    0    2    3    0    3\n",
      "     2    0]\n",
      " [   0    0    0    0    4  423    0    0    0    0    0    0    0    3\n",
      "     8    0]\n",
      " [   0    0    0    0    1    0   11    5    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   4    0    0    0    2    0    0  281    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    6    0    0    0    6    0\n",
      "     0    0]\n",
      " [   0   36    1    1    0    2    0    0    1  469   63   10    0    0\n",
      "     0    0]\n",
      " [   0   83   42    3    3    6    0    0    1   48 1275    8    0    0\n",
      "     4    0]\n",
      " [   0   12   15    7    1    0    0    0    0    9   14  295    0    0\n",
      "     1    2]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0  122    0\n",
      "     0    0]\n",
      " [   0    0    0    0    8    0    0    0    0    0    1    0    0  717\n",
      "    33    0]\n",
      " [   0    0    0    2    4   14    0    0    2    1    2    0    7   37\n",
      "   163    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    5    0    0    0\n",
      "     0   51]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8583739837398374"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p=45\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 45)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imssi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  18    0    0    0    0    0    0    8    0    1    0    0    0    0\n",
      "     0    0]\n",
      " [   0  702   12   10    0    0    0    0    0   35   84   14    0    0\n",
      "     0    0]\n",
      " [   0   25  396   15    0    0    0    0    0    4   42   16    0    0\n",
      "     0    0]\n",
      " [   0   11   26   92    0    1    0    1    0    3    4    4    0    0\n",
      "     0    0]\n",
      " [   0    2    0    1  274    4    0    0    0    0    2    3    0    2\n",
      "     2    0]\n",
      " [   0    0    0    0    4  424    0    0    0    0    0    0    0    3\n",
      "     7    0]\n",
      " [   0    0    0    0    1    0   11    5    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   1    0    0    0    2    0    0  284    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    6    0    0    0    5    0\n",
      "     1    0]\n",
      " [   0   33    2    1    0    2    0    0    1  478   58    8    0    0\n",
      "     0    0]\n",
      " [   0   76   40    3    3    7    0    0    0   49 1283    8    0    0\n",
      "     4    0]\n",
      " [   0    9   15    7    1    0    0    0    0    7   14  300    0    0\n",
      "     1    2]\n",
      " [   0    0    0    0    0    0    0    0    0    1    0    0  122    0\n",
      "     0    0]\n",
      " [   0    0    0    0    5    0    0    0    0    0    1    0    0  718\n",
      "    35    0]\n",
      " [   0    0    0    2    2   14    0    0    2    1    1    0    6   38\n",
      "   166    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    5    0    0    0\n",
      "     0   51]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8658536585365854"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p=50\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 50)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imssi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  18    0    0    0    0    0    0    8    0    1    0    0    0    0\n",
      "     0    0]\n",
      " [   0  707    9   10    0    0    0    0    0   34   84   13    0    0\n",
      "     0    0]\n",
      " [   0   22  402   15    0    0    0    0    0    3   41   15    0    0\n",
      "     0    0]\n",
      " [   0    8   26   93    0    1    0    1    0    3    3    7    0    0\n",
      "     0    0]\n",
      " [   0    2    0    0  275    4    0    0    0    0    3    3    0    2\n",
      "     1    0]\n",
      " [   0    0    0    0    4  427    0    0    0    0    0    0    0    2\n",
      "     5    0]\n",
      " [   0    0    0    0    1    0   11    5    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    1    0    0  286    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    7    0    0    0    4    0\n",
      "     1    0]\n",
      " [   0   26    1    1    0    2    0    0    1  481   60   11    0    0\n",
      "     0    0]\n",
      " [   0   72   37    1    5    7    0    0    0   50 1289    8    0    0\n",
      "     4    0]\n",
      " [   0    9   15    7    0    0    0    0    0    9   15  298    0    0\n",
      "     1    2]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0  122    0\n",
      "     0    0]\n",
      " [   0    0    0    0    6    0    0    0    0    0    1    0    0  721\n",
      "    31    0]\n",
      " [   0    0    0    2    3   13    0    0    2    1    1    0    4   38\n",
      "   168    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    4    0    0    0\n",
      "     0   52]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8710569105691057"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p=55\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 55)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imssi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  17    0    0    0    0    0    0    9    0    1    0    0    0    0\n",
      "     0    0]\n",
      " [   0  709    9   10    0    0    0    0    0   37   81   11    0    0\n",
      "     0    0]\n",
      " [   0   20  408   15    0    0    0    0    0    2   36   17    0    0\n",
      "     0    0]\n",
      " [   0    9   28   90    0    1    0    1    0    3    5    5    0    0\n",
      "     0    0]\n",
      " [   0    2    0    1  276    4    0    0    0    1    0    3    0    2\n",
      "     1    0]\n",
      " [   0    0    0    0    4  428    0    0    0    0    0    0    0    1\n",
      "     5    0]\n",
      " [   0    0    0    0    1    0   11    5    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   1    0    0    0    1    0    0  285    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    6    0    0    0    5    0\n",
      "     1    0]\n",
      " [   0   25    1    1    0    2    0    0    1  487   56   10    0    0\n",
      "     0    0]\n",
      " [   0   66   36    1    6    6    0    0    1   50 1298    6    0    0\n",
      "     3    0]\n",
      " [   0   10   14    5    0    0    0    0    0    8   15  301    0    0\n",
      "     1    2]\n",
      " [   0    0    0    0    0    0    0    0    0    1    0    0  122    0\n",
      "     0    0]\n",
      " [   0    0    0    0    4    0    0    0    0    0    0    0    0  729\n",
      "    26    0]\n",
      " [   0    0    0    3    2   12    0    0    2    0    1    0    4   38\n",
      "   170    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    3    0    0    0\n",
      "     0   53]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8764227642276423"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p=60\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 60)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imssi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  19    0    0    0    0    0    0    7    0    1    0    0    0    0\n",
      "     0    0]\n",
      " [   0  715    8   11    0    0    0    0    0   42   71   10    0    0\n",
      "     0    0]\n",
      " [   0   17  413   15    0    0    0    0    0    3   34   16    0    0\n",
      "     0    0]\n",
      " [   0    6   25   96    1    1    0    1    0    3    5    4    0    0\n",
      "     0    0]\n",
      " [   0    1    0    2  279    2    0    0    0    0    2    2    0    1\n",
      "     1    0]\n",
      " [   0    0    0    0    4  429    0    0    0    0    0    0    0    1\n",
      "     4    0]\n",
      " [   0    0    0    0    1    0   11    5    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   1    0    0    0    1    0    0  285    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    6    0    0    0    5    0\n",
      "     1    0]\n",
      " [   0   30    2    1    0    2    0    0    1  485   53    9    0    0\n",
      "     0    0]\n",
      " [   0   69   34    0    6    6    0    0    1   52 1295    6    0    0\n",
      "     4    0]\n",
      " [   0    7    9    6    0    0    0    0    0    8   14  310    0    0\n",
      "     1    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0  122    0\n",
      "     0    0]\n",
      " [   0    0    0    0    4    0    0    0    0    0    0    0    0  738\n",
      "    17    0]\n",
      " [   0    0    0    3    3   11    0    0    2    0    1    0    5   38\n",
      "   169    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    3    0    0    0\n",
      "     0   53]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8821138211382114"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p=70\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 70)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imssi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  19    0    0    0    0    0    0    7    0    0    0    1    0    0\n",
      "     0    0]\n",
      " [   0  727    8   10    0    0    0    0    0   33   70    9    0    0\n",
      "     0    0]\n",
      " [   0   19  409   15    0    0    0    0    0    3   35   17    0    0\n",
      "     0    0]\n",
      " [   0    4   27   98    1    1    0    1    0    2    5    3    0    0\n",
      "     0    0]\n",
      " [   0    1    0    2  279    2    0    0    0    0    3    2    0    0\n",
      "     1    0]\n",
      " [   0    0    0    0    4  430    0    0    0    0    0    0    0    1\n",
      "     3    0]\n",
      " [   0    0    0    0    1    0   11    5    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   1    0    0    0    2    0    0  284    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    0    0    0    6    0    0    0    5    0\n",
      "     1    0]\n",
      " [   0   28    3    1    0    2    0    0    1  489   52    7    0    0\n",
      "     0    0]\n",
      " [   0   69   34    1    5    6    0    0    1   50 1297    7    0    0\n",
      "     3    0]\n",
      " [   0    7   10    8    0    0    0    0    0    9   15  305    0    0\n",
      "     1    1]\n",
      " [   0    0    0    0    0    0    0    0    0    1    0    0  122    0\n",
      "     0    0]\n",
      " [   0    0    0    0    5    0    0    0    0    0    0    0    0  735\n",
      "    19    0]\n",
      " [   0    0    0    3    4    9    0    0    2    0    1    0    2   38\n",
      "   173    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    3    0    0    0\n",
      "     0   53]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8840650406504065"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p=80\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 80)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM run for different kernels (p=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.791869918699187"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LINEAR KERNEL\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 40)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'linear', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imssi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8147967479674797"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POLY KERNEL\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 40)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'poly', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imssi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8521951219512195"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RBF KERNEL\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 40)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'rbf', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imssi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18715447154471546"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SIGMOID KERNEL\n",
    "\n",
    "# importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 40)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "#Training the SVM model\n",
    "classifier = SVC(C = 100, kernel = 'sigmoid', cache_size = 10*1024)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "#importing\n",
    "X = df_new.iloc[:, :-1].values\n",
    "y = df_new.iloc[:, -1].values\n",
    "\n",
    "#Splitting into training and Testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=11, stratify=y)\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 50, criterion ='entropy', random_state=0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  20    0    0    0    0    0    0    6    0    0    1    0    0    0\n",
      "     0    0]\n",
      " [   0  633    9    6    1    1    0    0    0   64  130   13    0    0\n",
      "     0    0]\n",
      " [   0   20  340    8    0    0    0    0    0    5   90   35    0    0\n",
      "     0    0]\n",
      " [   0    9   18   80    1    1    0    1    0    2   21    9    0    0\n",
      "     0    0]\n",
      " [   0    1    0    1  267    4    0    0    0    0    4    2    0    7\n",
      "     4    0]\n",
      " [   0    0    0    0    5  426    0    0    0    0    0    0    1    0\n",
      "     6    0]\n",
      " [   0    0    0    0    1    0   10    6    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   1    0    0    0    5    0    0  281    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    0    5    0    0    5    0    0    0    2    0\n",
      "     0    0]\n",
      " [   0   17   12    0    0    2    0    1    1  464   80    6    0    0\n",
      "     0    0]\n",
      " [   0   43   18    3    4    5    0    0    2   29 1354   12    0    0\n",
      "     3    0]\n",
      " [   0   14   20    4    0    0    0    0    0   10   46  259    0    0\n",
      "     1    2]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0  119    0\n",
      "     3    0]\n",
      " [   0    0    0    0    7    0    0    0    0    0    0    0    0  731\n",
      "    21    0]\n",
      " [   0    0    0    1    4   33    0    0    1    0    1    1    9   60\n",
      "   122    0]\n",
      " [   0    1    1    0    0    0    0    0    0    0    6    0    0    0\n",
      "     0   48]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8388617886178862"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest after PCA\n",
    "#Applying PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 40)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 50, criterion ='entropy', random_state=0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1    0    0    0    0    0    0   25    0    1    0    0    0    0\n",
      "     0    0]\n",
      " [   0  569   11    4    0    1    0    0    0   51  212    6    0    0\n",
      "     1    2]\n",
      " [   0   53  258    3    0    0    0    0    0    9  163   12    0    0\n",
      "     0    0]\n",
      " [   0   35   16   39    0    1    0    1    0    4   37    9    0    0\n",
      "     0    0]\n",
      " [   0    4    0    1  251    7    0    2    0    0    1    2    0   21\n",
      "     0    1]\n",
      " [   0    0    0    0    1  424    0    0    0    0    0    0    0    7\n",
      "     6    0]\n",
      " [   0    0    0    0    1    0   10    6    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   0    0    0    0    4    0    0  282    0    0    0    0    0    0\n",
      "     1    0]\n",
      " [   0    0    0    0    0    5    0    0    3    0    0    0    1    1\n",
      "     2    0]\n",
      " [   0   23    4    0    1    4    0    0    0  397  142   12    0    0\n",
      "     0    0]\n",
      " [   0  102   22    0    2   14    0    0    0   28 1299    5    0    0\n",
      "     1    0]\n",
      " [   0   51   19    3    1    0    0    0    0   23  103  153    0    0\n",
      "     1    2]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0  122    0\n",
      "     0    0]\n",
      " [   0    0    0    0    5    0    0    0    0    0    0    0    0  749\n",
      "     5    0]\n",
      " [   0    1    1    0    7   46    0    4    0    0    0    0    6   76\n",
      "    90    1]\n",
      " [   0    6    0    0    0    0    0    0    0    0    1    0    0    0\n",
      "     0   49]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7635772357723577"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
